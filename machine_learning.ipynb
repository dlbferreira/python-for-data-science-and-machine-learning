{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "machine_learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOyvjlo4sFXhZpklY8HPtBN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dlbferreira/python-for-data-science-and-machine-learning/blob/main/machine_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2r8lc3P-vEAS"
      },
      "source": [
        "# **Machine Learning**\r\n",
        "\r\n",
        "To fix the issue, data is often split into **3 sets**\r\n",
        "\r\n",
        "\r\n",
        "*   Training Data\r\n",
        "\r\n",
        "Used to train model parameters\r\n",
        "*   Validation Data\r\n",
        "\r\n",
        "Used to determine what model hyperparameters to adjust\r\n",
        "*   Test Data\r\n",
        "\r\n",
        "Used to get some final performance metric\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9FJ2yL535Ng"
      },
      "source": [
        "## **Model Evaluation**\r\n",
        "\r\n",
        "*   Classification metrics in more detail! The key classification metrics we need to understand are:\r\n",
        "\r\n",
        "1.   Accuracy\r\n",
        "2.   Recall\r\n",
        "3.   Precision\r\n",
        "4.   F1-Score\r\n",
        "\r\n",
        "*   Typically in any classification task your model can only achieve two results:\r\n",
        "> Either your model was **correct** in its prediction.\r\n",
        "> Or your model was **incorrect** in its prediction.\r\n",
        "\r\n",
        "*   Fortunately incorrect vs correct expands to situations where you have multiple classes.\r\n",
        "\r\n",
        "---\r\n",
        "*   For the purposes of explaining the metrics, let's image a **binary classificatioon** situation, where we only have two available classes.\r\n",
        "\r\n",
        "**For example:** predict if an image is a dog or a cat.\r\n",
        "Since this is supervise learning, we'll:\r\n",
        "  1. **fit/train** a model on **training data**\r\n",
        "  2. **test** the model on **testing data**.\r\n",
        "  3. have the model's predictions from the **X_test** data, we compare it to the **true y values** (correct labels).\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9n6Q74sQ9hoz"
      },
      "source": [
        "## **Accuracy**\r\n",
        "\r\n",
        "Accuracy in classification problems is the **number of correct predictions** made by the model divided by the **total number of predictions**. Is useful when target classes are well balanced\r\n",
        "\r\n",
        "* For example, if the X_test set was 100 images and our model **correctly** predicted 80 images, then we have **80/100 = 0.8** or **80% accuracy.**\r\n",
        "\r\n",
        "Accuracy is **not** a good choice with **unbalanced** classes!\r\n",
        "* Image we had 99 images of dogs and 1 image of a cat.\r\n",
        "* If our model was simply a line that always preficted **dog** we would get 99% accuracy!\r\n",
        "* In this situtuin we'll want to understand **recall** and **precision.**\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UpgRKWaEbD7"
      },
      "source": [
        "## **Recall**\r\n",
        "\r\n",
        "Ability of a model to find all the relevant cases within a dataset. The precise definition of recall is the number of true positives **divided by** the number of true positives plus the number of false negatives.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5vGLNUVFK1M"
      },
      "source": [
        "## **Precision**\r\n",
        "\r\n",
        "Ability of a classification model to identify only the relevant data points. Precision is defined as the number of true positives divided by the number of tru positives plus the number of flase positives.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeOhRRSNFpaT"
      },
      "source": [
        "## **Recall and Precision**\r\n",
        "\r\n",
        "Often you have a trade-off between Recall and Precision.\r\n",
        "\r\n",
        "While **recall** express the ability to find all relevant instances in a dataset, **precision** express the porportion of the data points our model says was relevant actually wew relevant.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKOJboTzMjaa"
      },
      "source": [
        "## **F1-Score**\r\n",
        "\r\n",
        "The F1 score is the harmonic mean of precision and recall taking both metrics into account in the following equation:\r\n",
        "\r\n",
        "$$F_1 = 2* \\frac{precision - recall}{precision + recall } $$\r\n",
        "\r\n",
        "\r\n",
        "We use ther harmonic mean instead of a simple average because it punishes extreme values.\r\n",
        "\r\n",
        "A classifier with a precision of 1.0 and a recall of 0.0 has a simple average of 0.5 but an F1 score of 0.\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Us7MfdGfQtET"
      },
      "source": [
        "## **Evaluating Performance**\r\n",
        "### **Regression**\r\n",
        "\r\n",
        "Regression is a task when a model attempts to predict continuous values (inlike ctegorical values, which is calssification).\r\n",
        "* For example: attempting to predict the price of a house given its features is a **regression task.**\r\n",
        "\r\n",
        "Attempting to predict the country a house is in given its features would be a classification task.\r\n",
        "\r\n",
        "Some of the most common evaluation metrics fo regression:\r\n",
        "* **Mean Absoulute Error (MAE)**\r\n",
        "> This is the mean of the absolute value of erros.\r\n",
        "\r\n",
        "* **Mean Squared Error (MSE)**\r\n",
        "> This is the mean of the squared errors.\r\n",
        "\r\n",
        "* **Root Mean Square Error (RMSE)**\r\n",
        "> This is the root of the mean of the squared errors.\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9H6nWFNVAcy"
      },
      "source": [
        "## **Library**\r\n",
        "\r\n",
        "Using the **Scikit Learn** package.\r\n",
        "\r\n",
        "It's the most popular machine learning package for Python and has a lot of algorithms built-in!\r\n",
        "\r\n",
        "> **conda install scikit-learn** or **pip install scikit-learn**\r\n",
        "\r\n",
        "Every algorithm is exposed in scikit-learn via an \"Estimator\" first you'll import the model, the general form is:\r\n",
        "\r\n",
        "> **from sklearn.family import Model**\r\n",
        ">\r\n",
        "For example:\r\n",
        ">**from sklearn.linear_model import LinearRegression**\r\n",
        "\r\n",
        "We have split the data, we can train/fit our model on the training data. This is done through the model.fit() method:\r\n",
        "\r\n",
        "> **model.fit(X_train,y_train)**\r\n",
        "\r\n",
        "\r\n"
      ]
    }
  ]
}